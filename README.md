# ETL Project

Este es un repositorio de ejemplo para un proyecto de ETL (Extract, Transform, Load) en Databricks. El proyecto incluye scripts, notebooks, trabajos y configuraciones necesarias para realizar el proceso de ETL en un entorno distribuido.

## Estructura del Repositorio

- `notebooks/`: Contiene notebooks de Databricks para el desarrollo y análisis de datos.
- `scripts/`: Directorio para scripts Python que contienen funciones relacionadas con el proceso ETL.
- `jobs/`: Directorio que contiene scripts Python para los trabajos de producción en Databricks.
- `tests/`: Directorio que contiene pruebas unitarias para los scripts.
- `configs/`: Aquí se almacenan archivos de configuración como JSON para el ETL y la configuración de registro.
- `data/`: Directorio que contiene datos brutos y procesados.
- `requirements.txt`: Archivo que lista las bibliotecas Python necesarias para ejecutar el proyecto.
- `README.md`: Este archivo que proporciona una descripción general del repositorio y sus contenidos.

## Requisitos

- Python 3.x
- Bibliotecas especificadas en `requirements.txt`
- Acceso a un entorno de Databricks

## Uso

1. Clona este repositorio en tu entorno de desarrollo.
2. Instala las bibliotecas necesarias ejecutando `pip install -r requirements.txt`.
3. Configura tu entorno de Databricks y carga los notebooks y scripts según sea necesario.
4. Ejecuta los notebooks y scripts para realizar el proceso de ETL.

